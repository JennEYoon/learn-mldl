From Alice Robie to All Panelists:  12:11 PM
https://www.google.com/url?sa=i&url=http%3A%2F%2Frasbt.github.io%2Fmlxtend%2Fuser_guide%2Fgeneral_concepts%2Fgradient-optimization%2F&psig=AOvVaw3JeDR5dQKKe5dwxgwXtkLT&ust=1598631072273000&source=images&cd=vfe&ved=0CAMQjB1qFwoTCKjLq_viu-sCFQAAAAAdAAAAABAD
From Me to Alice Robie:  (Privately) 12:15 PM
https://www.youtube.com/watch?v=IHZwWFHWa-w
From Me to All Panelists:  12:15 PM
https://www.youtube.com/watch?v=IHZwWFHWa-wFrom Alice Robie to All Panelists:  12:16 PM
https://www.mltut.com/stochastic-gradient-descent-a-super-easy-complete-guide/
From Andrea to All Panelists:  12:16 PM
thank you
From Alice Robie to All Panelists:  12:44 PM
np.amax(x) finds max of lumpy array
From Lisa Taylor to All Panelists:  12:45 PM
https://www.fast.ai/
From Alice Robie to All Panelists:  12:46 PM
*lumpy = numpy
From Teri Ngo to All Panelists:  12:52 PM
Here is another one with over 22,000 students.
https://hhmi.udemy.com/course/data-science-and-machine-learning-with-python-hands-on/learn/lecture/15109038#overview
This one has some a python refresher
From Lisa Taylor to All Panelists:  12:55 PM
https://hhmi.udemy.com/course/python-programming-projects/
From Nai-Wen Tien to All Panelists:  12:56 PM
I was reading the documentation page of "sklearn.linear_model.LinearRegression" you just shared,  and it said it's "Ordinary least squares Linear Regression." So I guess it's using the matrix approach rather than the gradient descent?
From Lisa Taylor to All Panelists:  12:56 PM
Here’s a short into to python class
https://hhmi.udemy.com/course/python-programming-projects/